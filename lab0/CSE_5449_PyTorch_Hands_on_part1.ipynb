{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ac7c6e78",
      "metadata": {
        "papermill": {
          "duration": 0.021419,
          "end_time": "2023-05-03T17:05:32.422045",
          "exception": false,
          "start_time": "2023-05-03T17:05:32.400626",
          "status": "completed"
        },
        "tags": [],
        "id": "ac7c6e78"
      },
      "source": [
        "\n",
        "# Tutorial 1: Introduction to PyTorch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72ffd3bf",
      "metadata": {
        "papermill": {
          "duration": 0.012764,
          "end_time": "2023-05-03T17:05:32.478684",
          "exception": false,
          "start_time": "2023-05-03T17:05:32.465920",
          "status": "completed"
        },
        "tags": [],
        "id": "72ffd3bf"
      },
      "source": [
        "## Setup\n",
        "Adapted from https://colab.research.google.com/github/PytorchLightning/lightning-tutorials/blob/publication/.notebooks/course_UvA-DL/01-introduction-to-pytorch.ipynb#scrollTo=c5bb5655"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92651a1b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:32.505649Z",
          "iopub.status.busy": "2023-05-03T17:05:32.505283Z",
          "iopub.status.idle": "2023-05-03T17:05:36.066029Z",
          "shell.execute_reply": "2023-05-03T17:05:36.064653Z"
        },
        "id": "92651a1b",
        "lines_to_next_cell": 0,
        "papermill": {
          "duration": 3.577588,
          "end_time": "2023-05-03T17:05:36.068960",
          "exception": false,
          "start_time": "2023-05-03T17:05:32.491372",
          "status": "completed"
        },
        "tags": [],
        "outputId": "f1325a7f-5f6f-48df-d1ca-0aeabb636df7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.0/727.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.7/70.7 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m596.7/596.7 kB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m370.9/370.9 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.9/69.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install --quiet \"urllib3\" \"pytorch-lightning>=1.4, <2.1.0\" \"setuptools==67.7.2\" \"torch>=1.8.1, <2.1.0\" \"torchmetrics>=0.7, <0.12\" \"matplotlib>=3.0.0, <3.8.0\" \"ipython[notebook]==7.34.0\" \"lightning>=2.0.0rc0\" \"matplotlib\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f91dd62d",
      "metadata": {
        "papermill": {
          "duration": 0.012723,
          "end_time": "2023-05-03T17:05:36.099348",
          "exception": false,
          "start_time": "2023-05-03T17:05:36.086625",
          "status": "completed"
        },
        "tags": [],
        "id": "f91dd62d"
      },
      "source": [
        "Set up env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef060fb4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:36.126572Z",
          "iopub.status.busy": "2023-05-03T17:05:36.126192Z",
          "iopub.status.idle": "2023-05-03T17:05:37.362410Z",
          "shell.execute_reply": "2023-05-03T17:05:37.361159Z"
        },
        "papermill": {
          "duration": 1.253162,
          "end_time": "2023-05-03T17:05:37.365219",
          "exception": false,
          "start_time": "2023-05-03T17:05:36.112057",
          "status": "completed"
        },
        "tags": [],
        "id": "ef060fb4"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib_inline.backend_inline\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "from matplotlib.colors import to_rgba\n",
        "from torch import Tensor\n",
        "from tqdm.notebook import tqdm  # Progress bar\n",
        "\n",
        "matplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\", \"pdf\")  # For export"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3007f3a4",
      "metadata": {
        "papermill": {
          "duration": 0.01263,
          "end_time": "2023-05-03T17:05:37.394212",
          "exception": false,
          "start_time": "2023-05-03T17:05:37.381582",
          "status": "completed"
        },
        "tags": [],
        "id": "3007f3a4"
      },
      "source": [
        "## The Basics of PyTorch\n",
        "\n",
        "As a first step, we can check the torch version:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee4f9313",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:37.421480Z",
          "iopub.status.busy": "2023-05-03T17:05:37.420955Z",
          "iopub.status.idle": "2023-05-03T17:05:37.427741Z",
          "shell.execute_reply": "2023-05-03T17:05:37.426499Z"
        },
        "papermill": {
          "duration": 0.022416,
          "end_time": "2023-05-03T17:05:37.429291",
          "exception": false,
          "start_time": "2023-05-03T17:05:37.406875",
          "status": "completed"
        },
        "tags": [],
        "id": "ee4f9313",
        "outputId": "0aaf5d46-3769-484b-c71a-79c750a5866d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using torch 2.0.1+cu118\n"
          ]
        }
      ],
      "source": [
        "print(\"Using torch\", torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91916ed0",
      "metadata": {
        "papermill": {
          "duration": 0.012691,
          "end_time": "2023-05-03T17:05:37.460216",
          "exception": false,
          "start_time": "2023-05-03T17:05:37.447525",
          "status": "completed"
        },
        "tags": [],
        "id": "91916ed0"
      },
      "source": [
        "As in every machine learning framework, PyTorch provides functions that are stochastic like generating random numbers.\n",
        "However, a very good practice is to setup your code to be reproducible with the exact same random numbers.\n",
        "This is why we set a seed below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ffbb15c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:37.488098Z",
          "iopub.status.busy": "2023-05-03T17:05:37.487544Z",
          "iopub.status.idle": "2023-05-03T17:05:37.498395Z",
          "shell.execute_reply": "2023-05-03T17:05:37.497297Z"
        },
        "papermill": {
          "duration": 0.027807,
          "end_time": "2023-05-03T17:05:37.500815",
          "exception": false,
          "start_time": "2023-05-03T17:05:37.473008",
          "status": "completed"
        },
        "tags": [],
        "id": "4ffbb15c",
        "outputId": "896a52fa-e464-4066-8f3a-a5d444ff2f19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7afc2c0f8e10>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "torch.manual_seed(42)  # Setting the seed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dbdfcd6",
      "metadata": {
        "papermill": {
          "duration": 0.01277,
          "end_time": "2023-05-03T17:05:37.530254",
          "exception": false,
          "start_time": "2023-05-03T17:05:37.517484",
          "status": "completed"
        },
        "tags": [],
        "id": "6dbdfcd6"
      },
      "source": [
        "### Tensors\n",
        "\n",
        "The name \"tensor\" is a generalization of concepts you already know.\n",
        "For instance, a vector is a 1-D tensor, and a matrix a 2-D tensor.\n",
        "\n",
        "#### Initialization\n",
        "\n",
        "Let's first start by looking at different ways of creating a tensor!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "899e4216",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:37.559861Z",
          "iopub.status.busy": "2023-05-03T17:05:37.559469Z",
          "iopub.status.idle": "2023-05-03T17:05:37.570514Z",
          "shell.execute_reply": "2023-05-03T17:05:37.569642Z"
        },
        "papermill": {
          "duration": 0.029322,
          "end_time": "2023-05-03T17:05:37.572743",
          "exception": false,
          "start_time": "2023-05-03T17:05:37.543421",
          "status": "completed"
        },
        "tags": [],
        "id": "899e4216",
        "outputId": "f9441f31-aa27-445c-bf1f-67ac6b6b36cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[9.9130e+04, 4.4118e-41, 9.9130e+04, 4.4118e-41],\n",
            "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "         [1.2845e+31, 1.6045e+02, 1.3926e+19, 8.6543e+05]],\n",
            "\n",
            "        [[1.4217e+19, 8.7765e+05, 5.1580e-02, 2.0535e-19],\n",
            "         [1.8617e+25, 5.9423e-02, 1.5870e-19, 5.2053e+34],\n",
            "         [1.8500e+20, 2.0333e+32, 1.1259e+24, 1.1700e-19]]])\n"
          ]
        }
      ],
      "source": [
        "x = Tensor(2, 3, 4)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e53987bf",
      "metadata": {
        "papermill": {
          "duration": 0.012786,
          "end_time": "2023-05-03T17:05:37.602262",
          "exception": false,
          "start_time": "2023-05-03T17:05:37.589476",
          "status": "completed"
        },
        "tags": [],
        "id": "e53987bf"
      },
      "source": [
        "The function `torch.Tensor` allocates memory for the desired tensor, but reuses any values that have already been in the memory.\n",
        "To directly assign values to the tensor during initialization, there are many alternatives including:\n",
        "\n",
        "* `torch.zeros`: Creates a tensor filled with zeros\n",
        "* `torch.ones`: Creates a tensor filled with ones\n",
        "* `torch.rand`: Creates a tensor with random values uniformly sampled between 0 and 1\n",
        "* `torch.randn`: Creates a tensor with random values sampled from a normal distribution with mean 0 and variance 1\n",
        "* `torch.arange`: Creates a tensor containing the values $N,N+1,N+2,...,M$\n",
        "* `torch.Tensor` (input list): Creates a tensor from the list elements you provide"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f6faaa4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:37.629725Z",
          "iopub.status.busy": "2023-05-03T17:05:37.629088Z",
          "iopub.status.idle": "2023-05-03T17:05:37.635741Z",
          "shell.execute_reply": "2023-05-03T17:05:37.634662Z"
        },
        "papermill": {
          "duration": 0.022253,
          "end_time": "2023-05-03T17:05:37.637352",
          "exception": false,
          "start_time": "2023-05-03T17:05:37.615099",
          "status": "completed"
        },
        "tags": [],
        "id": "5f6faaa4",
        "outputId": "a49b9e68-a16a-4f94-875e-004c9b438806",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n"
          ]
        }
      ],
      "source": [
        "# Create a tensor from a (nested) list\n",
        "x = Tensor([[1, 2], [3, 4]])\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c80d2c4f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:37.667304Z",
          "iopub.status.busy": "2023-05-03T17:05:37.666990Z",
          "iopub.status.idle": "2023-05-03T17:05:37.672586Z",
          "shell.execute_reply": "2023-05-03T17:05:37.671641Z"
        },
        "papermill": {
          "duration": 0.020746,
          "end_time": "2023-05-03T17:05:37.673995",
          "exception": false,
          "start_time": "2023-05-03T17:05:37.653249",
          "status": "completed"
        },
        "tags": [],
        "id": "c80d2c4f",
        "outputId": "96e9bf3c-7efe-4f22-f337-b175435ad961",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.9811, 0.0874, 0.0041, 0.1088],\n",
            "         [0.1637, 0.7025, 0.6790, 0.9155],\n",
            "         [0.2418, 0.1591, 0.7653, 0.2979]],\n",
            "\n",
            "        [[0.8035, 0.3813, 0.7860, 0.1115],\n",
            "         [0.2477, 0.6524, 0.6057, 0.3725],\n",
            "         [0.7980, 0.8399, 0.1374, 0.2331]]])\n"
          ]
        }
      ],
      "source": [
        "# Create a tensor with random values between 0 and 1 with the shape [2, 3, 4]\n",
        "x = torch.rand(2, 3, 4)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a66db10d",
      "metadata": {
        "papermill": {
          "duration": 0.013051,
          "end_time": "2023-05-03T17:05:37.703196",
          "exception": false,
          "start_time": "2023-05-03T17:05:37.690145",
          "status": "completed"
        },
        "tags": [],
        "id": "a66db10d"
      },
      "source": [
        "You can obtain the shape of a tensor in the same way as in numpy (`x.shape`), or using the `.size` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc8880b0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:37.730771Z",
          "iopub.status.busy": "2023-05-03T17:05:37.730397Z",
          "iopub.status.idle": "2023-05-03T17:05:37.737514Z",
          "shell.execute_reply": "2023-05-03T17:05:37.736426Z"
        },
        "papermill": {
          "duration": 0.022978,
          "end_time": "2023-05-03T17:05:37.739240",
          "exception": false,
          "start_time": "2023-05-03T17:05:37.716262",
          "status": "completed"
        },
        "tags": [],
        "id": "cc8880b0",
        "outputId": "92acc177-a3a4-4880-c9ab-eef3d6520d3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: torch.Size([2, 3, 4])\n",
            "Size: torch.Size([2, 3, 4])\n",
            "Size: 2 3 4\n"
          ]
        }
      ],
      "source": [
        "shape = x.shape\n",
        "print(\"Shape:\", x.shape)\n",
        "\n",
        "size = x.size()\n",
        "print(\"Size:\", size)\n",
        "\n",
        "dim1, dim2, dim3 = x.size()\n",
        "print(\"Size:\", dim1, dim2, dim3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cc138df",
      "metadata": {
        "papermill": {
          "duration": 0.01305,
          "end_time": "2023-05-03T17:05:37.768923",
          "exception": false,
          "start_time": "2023-05-03T17:05:37.755873",
          "status": "completed"
        },
        "tags": [],
        "id": "5cc138df"
      },
      "source": [
        "#### Tensor to Numpy, and Numpy to Tensor\n",
        "\n",
        "Tensors can be converted to numpy arrays, and numpy arrays back to tensors.\n",
        "To transform a numpy array into a tensor, we can use the function `torch.from_numpy`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2015edfe",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:37.796407Z",
          "iopub.status.busy": "2023-05-03T17:05:37.796098Z",
          "iopub.status.idle": "2023-05-03T17:05:37.801989Z",
          "shell.execute_reply": "2023-05-03T17:05:37.801044Z"
        },
        "papermill": {
          "duration": 0.021433,
          "end_time": "2023-05-03T17:05:37.803443",
          "exception": false,
          "start_time": "2023-05-03T17:05:37.782010",
          "status": "completed"
        },
        "tags": [],
        "id": "2015edfe",
        "outputId": "09726f2f-6154-40be-850e-0d47d667514e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numpy array: [[1 2]\n",
            " [3 4]]\n",
            "PyTorch tensor: tensor([[1, 2],\n",
            "        [3, 4]])\n"
          ]
        }
      ],
      "source": [
        "np_arr = np.array([[1, 2], [3, 4]])\n",
        "tensor = torch.from_numpy(np_arr)\n",
        "\n",
        "print(\"Numpy array:\", np_arr)\n",
        "print(\"PyTorch tensor:\", tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a4197e7",
      "metadata": {
        "papermill": {
          "duration": 0.013093,
          "end_time": "2023-05-03T17:05:37.833137",
          "exception": false,
          "start_time": "2023-05-03T17:05:37.820044",
          "status": "completed"
        },
        "tags": [],
        "id": "7a4197e7"
      },
      "source": [
        "To transform a PyTorch tensor back to a numpy array, we can use the function `.numpy()` on tensors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae72833d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:37.861016Z",
          "iopub.status.busy": "2023-05-03T17:05:37.860570Z",
          "iopub.status.idle": "2023-05-03T17:05:37.867294Z",
          "shell.execute_reply": "2023-05-03T17:05:37.866269Z"
        },
        "papermill": {
          "duration": 0.023351,
          "end_time": "2023-05-03T17:05:37.869693",
          "exception": false,
          "start_time": "2023-05-03T17:05:37.846342",
          "status": "completed"
        },
        "tags": [],
        "id": "ae72833d",
        "outputId": "c74d6e3c-2c8a-47cf-fdeb-9c9cf30bd5f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch tensor: tensor([0, 1, 2, 3])\n",
            "Numpy array: [0 1 2 3]\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.arange(4)\n",
        "np_arr = tensor.numpy()\n",
        "\n",
        "print(\"PyTorch tensor:\", tensor)\n",
        "print(\"Numpy array:\", np_arr)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf3c5f5a",
      "metadata": {
        "papermill": {
          "duration": 0.013245,
          "end_time": "2023-05-03T17:05:37.901856",
          "exception": false,
          "start_time": "2023-05-03T17:05:37.888611",
          "status": "completed"
        },
        "tags": [],
        "id": "cf3c5f5a"
      },
      "source": [
        "The conversion of tensors to numpy require the tensor to be on the CPU, and not the GPU (more on GPU support in a later section).\n",
        "In case you have a tensor on GPU, you need to call `.cpu()` on the tensor beforehand.\n",
        "Hence, you get a line like `np_arr = tensor.cpu().numpy()`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b617c9d",
      "metadata": {
        "papermill": {
          "duration": 0.013174,
          "end_time": "2023-05-03T17:05:37.928248",
          "exception": false,
          "start_time": "2023-05-03T17:05:37.915074",
          "status": "completed"
        },
        "tags": [],
        "id": "5b617c9d"
      },
      "source": [
        "#### Operations\n",
        "\n",
        "Most operations that exist in numpy, also exist in PyTorch.\n",
        "A full list of operations can be found in the [PyTorch documentation](https://pytorch.org/docs/stable/tensors.html#), but we will review the most important ones here.\n",
        "\n",
        "The simplest operation is to add two tensors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5bb5655",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:37.955942Z",
          "iopub.status.busy": "2023-05-03T17:05:37.955702Z",
          "iopub.status.idle": "2023-05-03T17:05:37.962441Z",
          "shell.execute_reply": "2023-05-03T17:05:37.961513Z"
        },
        "papermill": {
          "duration": 0.022619,
          "end_time": "2023-05-03T17:05:37.964136",
          "exception": false,
          "start_time": "2023-05-03T17:05:37.941517",
          "status": "completed"
        },
        "tags": [],
        "id": "c5bb5655",
        "outputId": "235f187a-c54d-430a-cbe1-83e42918bf19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X1 tensor([[0.9578, 0.3313, 0.3227],\n",
            "        [0.0162, 0.2137, 0.6249]])\n",
            "X2 tensor([[0.4340, 0.1371, 0.5117],\n",
            "        [0.1585, 0.0758, 0.2247]])\n",
            "Y tensor([[1.3918, 0.4683, 0.8345],\n",
            "        [0.1747, 0.2895, 0.8496]])\n"
          ]
        }
      ],
      "source": [
        "x1 = torch.rand(2, 3)\n",
        "x2 = torch.rand(2, 3)\n",
        "y = x1 + x2\n",
        "\n",
        "print(\"X1\", x1)\n",
        "print(\"X2\", x2)\n",
        "print(\"Y\", y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee68cea8",
      "metadata": {
        "papermill": {
          "duration": 0.013327,
          "end_time": "2023-05-03T17:05:37.995075",
          "exception": false,
          "start_time": "2023-05-03T17:05:37.981748",
          "status": "completed"
        },
        "tags": [],
        "id": "ee68cea8"
      },
      "source": [
        "Calling `x1 + x2` creates a new tensor containing the sum of the two inputs.\n",
        "However, we can also use in-place operations that are applied directly on the memory of a tensor.\n",
        "We therefore change the values of `x2` without the chance to re-accessing the values of `x2` before the operation.\n",
        "An example is shown below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc3f88ca",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:38.023297Z",
          "iopub.status.busy": "2023-05-03T17:05:38.022891Z",
          "iopub.status.idle": "2023-05-03T17:05:38.030029Z",
          "shell.execute_reply": "2023-05-03T17:05:38.029094Z"
        },
        "papermill": {
          "duration": 0.022797,
          "end_time": "2023-05-03T17:05:38.031336",
          "exception": false,
          "start_time": "2023-05-03T17:05:38.008539",
          "status": "completed"
        },
        "tags": [],
        "id": "cc3f88ca",
        "outputId": "bed0562e-a96b-41c8-dad0-69e0948bbd4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X1 (before) tensor([[0.0624, 0.1816, 0.9998],\n",
            "        [0.5944, 0.6541, 0.0337]])\n",
            "X2 (before) tensor([[0.1716, 0.3336, 0.5782],\n",
            "        [0.0600, 0.2846, 0.2007]])\n",
            "X1 (after) tensor([[0.0624, 0.1816, 0.9998],\n",
            "        [0.5944, 0.6541, 0.0337]])\n",
            "X2 (after) tensor([[0.2340, 0.5152, 1.5780],\n",
            "        [0.6545, 0.9386, 0.2343]])\n"
          ]
        }
      ],
      "source": [
        "x1 = torch.rand(2, 3)\n",
        "x2 = torch.rand(2, 3)\n",
        "print(\"X1 (before)\", x1)\n",
        "print(\"X2 (before)\", x2)\n",
        "\n",
        "x2.add_(x1)\n",
        "print(\"X1 (after)\", x1)\n",
        "print(\"X2 (after)\", x2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acc8e413",
      "metadata": {
        "papermill": {
          "duration": 0.013356,
          "end_time": "2023-05-03T17:05:38.062609",
          "exception": false,
          "start_time": "2023-05-03T17:05:38.049253",
          "status": "completed"
        },
        "tags": [],
        "id": "acc8e413"
      },
      "source": [
        "In-place operations are usually marked with a underscore postfix (for example `torch.add_` instead of `torch.add`).\n",
        "\n",
        "Another common operation aims at changing the shape of a tensor.\n",
        "A tensor of size (2,3) can be re-organized to any other shape with the same number of elements (e.g. a tensor of size (6), or (3,2), ...).\n",
        "In PyTorch, this operation is called `view`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e788250",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:38.091135Z",
          "iopub.status.busy": "2023-05-03T17:05:38.090687Z",
          "iopub.status.idle": "2023-05-03T17:05:38.096680Z",
          "shell.execute_reply": "2023-05-03T17:05:38.095667Z"
        },
        "papermill": {
          "duration": 0.021988,
          "end_time": "2023-05-03T17:05:38.098071",
          "exception": false,
          "start_time": "2023-05-03T17:05:38.076083",
          "status": "completed"
        },
        "tags": [],
        "id": "3e788250",
        "outputId": "8b8ee17b-114d-42ac-db23-a5e3ac86adb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X tensor([0, 1, 2, 3, 4, 5])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(6)\n",
        "print(\"X\", x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b89e4bbe",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:38.129101Z",
          "iopub.status.busy": "2023-05-03T17:05:38.128676Z",
          "iopub.status.idle": "2023-05-03T17:05:38.134024Z",
          "shell.execute_reply": "2023-05-03T17:05:38.133175Z"
        },
        "papermill": {
          "duration": 0.021397,
          "end_time": "2023-05-03T17:05:38.135436",
          "exception": false,
          "start_time": "2023-05-03T17:05:38.114039",
          "status": "completed"
        },
        "tags": [],
        "id": "b89e4bbe",
        "outputId": "5a66f8e3-1097-4645-abf9-600d3cdf9b6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n"
          ]
        }
      ],
      "source": [
        "x = x.view(2, 3)\n",
        "print(\"X\", x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccf150b2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:38.166003Z",
          "iopub.status.busy": "2023-05-03T17:05:38.165704Z",
          "iopub.status.idle": "2023-05-03T17:05:38.170859Z",
          "shell.execute_reply": "2023-05-03T17:05:38.170027Z"
        },
        "papermill": {
          "duration": 0.020789,
          "end_time": "2023-05-03T17:05:38.172162",
          "exception": false,
          "start_time": "2023-05-03T17:05:38.151373",
          "status": "completed"
        },
        "tags": [],
        "id": "ccf150b2",
        "outputId": "ad1b7752-6894-4bc2-cd10-b45d452dcae4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X tensor([[0, 3],\n",
            "        [1, 4],\n",
            "        [2, 5]])\n"
          ]
        }
      ],
      "source": [
        "x = x.permute(1, 0)  # Swapping dimension 0 and 1\n",
        "print(\"X\", x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6713371d",
      "metadata": {
        "papermill": {
          "duration": 0.013635,
          "end_time": "2023-05-03T17:05:38.201813",
          "exception": false,
          "start_time": "2023-05-03T17:05:38.188178",
          "status": "completed"
        },
        "tags": [],
        "id": "6713371d"
      },
      "source": [
        "Other commonly used operations include matrix multiplications, which are essential for neural networks.\n",
        "Quite often, we have an input vector $\\mathbf{x}$, which is transformed using a learned weight matrix $\\mathbf{W}$.\n",
        "There are multiple ways and functions to perform matrix multiplication, some of which we list below:\n",
        "\n",
        "* `torch.matmul`: Performs the matrix product over two tensors, where the specific behavior depends on the dimensions.\n",
        "If both inputs are matrices (2-dimensional tensors), it performs the standard matrix product.\n",
        "For higher dimensional inputs, the function supports broadcasting (for details see the [documentation](https://pytorch.org/docs/stable/generated/torch.matmul.html?highlight=matmul#torch.matmul)).\n",
        "Can also be written as `a @ b`, similar to numpy.\n",
        "* `torch.mm`: Performs the matrix product over two matrices, but doesn't support broadcasting (see [documentation](https://pytorch.org/docs/stable/generated/torch.mm.html?highlight=torch%20mm#torch.mm))\n",
        "* `torch.bmm`: Performs the matrix product with a support batch dimension.\n",
        "If the first tensor $T$ is of shape ($b\\times n\\times m$), and the second tensor $R$ ($b\\times m\\times p$), the output $O$ is of shape ($b\\times n\\times p$), and has been calculated by performing $b$ matrix multiplications of the submatrices of $T$ and $R$: $O_i = T_i @ R_i$\n",
        "* `torch.einsum`: Performs matrix multiplications and more (i.e. sums of products) using the Einstein summation convention.\n",
        "Explanation of the Einstein sum can be found in assignment 1.\n",
        "\n",
        "Usually, we use `torch.matmul` or `torch.bmm`. We can try a matrix multiplication with `torch.matmul` below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c71b963",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:38.230672Z",
          "iopub.status.busy": "2023-05-03T17:05:38.230328Z",
          "iopub.status.idle": "2023-05-03T17:05:38.235455Z",
          "shell.execute_reply": "2023-05-03T17:05:38.234607Z"
        },
        "papermill": {
          "duration": 0.021444,
          "end_time": "2023-05-03T17:05:38.237074",
          "exception": false,
          "start_time": "2023-05-03T17:05:38.215630",
          "status": "completed"
        },
        "tags": [],
        "id": "5c71b963",
        "outputId": "6ebf43a8-4948-4c18-edc2-5f2c85970b43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.ones(6)\n",
        "x = x.view(2, 3)\n",
        "print(\"X\", x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed6f026d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:38.269608Z",
          "iopub.status.busy": "2023-05-03T17:05:38.269310Z",
          "iopub.status.idle": "2023-05-03T17:05:38.274430Z",
          "shell.execute_reply": "2023-05-03T17:05:38.273597Z"
        },
        "papermill": {
          "duration": 0.022219,
          "end_time": "2023-05-03T17:05:38.277046",
          "exception": false,
          "start_time": "2023-05-03T17:05:38.254827",
          "status": "completed"
        },
        "tags": [],
        "id": "ed6f026d",
        "outputId": "291b705e-c837-4d0d-e447-c67c4d78cce1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "W = torch.ones(9).view(3, 3)  # We can also stack multiple operations in a single line\n",
        "print(\"W\", W)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b47d4b2d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:38.310912Z",
          "iopub.status.busy": "2023-05-03T17:05:38.310614Z",
          "iopub.status.idle": "2023-05-03T17:05:38.315702Z",
          "shell.execute_reply": "2023-05-03T17:05:38.314820Z"
        },
        "papermill": {
          "duration": 0.021778,
          "end_time": "2023-05-03T17:05:38.317360",
          "exception": false,
          "start_time": "2023-05-03T17:05:38.295582",
          "status": "completed"
        },
        "tags": [],
        "id": "b47d4b2d",
        "outputId": "69f1187f-9b8d-4361-c766-5adde24b19cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h tensor([[3., 3., 3.],\n",
            "        [3., 3., 3.]])\n"
          ]
        }
      ],
      "source": [
        "h = torch.matmul(x, W)  # Verify the result by calculating it by hand too!\n",
        "print(\"h\", h)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16cd52c8",
      "metadata": {
        "papermill": {
          "duration": 0.013855,
          "end_time": "2023-05-03T17:05:38.348131",
          "exception": false,
          "start_time": "2023-05-03T17:05:38.334276",
          "status": "completed"
        },
        "tags": [],
        "id": "16cd52c8"
      },
      "source": [
        "#### Indexing\n",
        "\n",
        "We often have the situation where we need to select a part of a tensor.\n",
        "Indexing works just like in numpy, so let's try it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4182c5b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:38.378139Z",
          "iopub.status.busy": "2023-05-03T17:05:38.377211Z",
          "iopub.status.idle": "2023-05-03T17:05:38.383830Z",
          "shell.execute_reply": "2023-05-03T17:05:38.382718Z"
        },
        "papermill": {
          "duration": 0.023157,
          "end_time": "2023-05-03T17:05:38.385233",
          "exception": false,
          "start_time": "2023-05-03T17:05:38.362076",
          "status": "completed"
        },
        "tags": [],
        "id": "b4182c5b",
        "outputId": "71118f5e-7399-425e-fa0e-966ed6323a1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(12).view(3, 4)\n",
        "print(\"X\", x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d690996",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:38.419864Z",
          "iopub.status.busy": "2023-05-03T17:05:38.419561Z",
          "iopub.status.idle": "2023-05-03T17:05:38.423728Z",
          "shell.execute_reply": "2023-05-03T17:05:38.422988Z"
        },
        "papermill": {
          "duration": 0.020487,
          "end_time": "2023-05-03T17:05:38.425310",
          "exception": false,
          "start_time": "2023-05-03T17:05:38.404823",
          "status": "completed"
        },
        "tags": [],
        "id": "4d690996",
        "outputId": "f0ed1eba-0694-43ac-dba3-7a63321556c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 5, 9])\n"
          ]
        }
      ],
      "source": [
        "print(x[:, 1])  # Second column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b000bee",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:38.457934Z",
          "iopub.status.busy": "2023-05-03T17:05:38.457511Z",
          "iopub.status.idle": "2023-05-03T17:05:38.463238Z",
          "shell.execute_reply": "2023-05-03T17:05:38.462230Z"
        },
        "papermill": {
          "duration": 0.022186,
          "end_time": "2023-05-03T17:05:38.464512",
          "exception": false,
          "start_time": "2023-05-03T17:05:38.442326",
          "status": "completed"
        },
        "tags": [],
        "id": "9b000bee",
        "outputId": "df67a07f-fc17-46f6-9b15-72125baa67b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3])\n"
          ]
        }
      ],
      "source": [
        "print(x[0])  # First row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae2e204d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:38.496309Z",
          "iopub.status.busy": "2023-05-03T17:05:38.496009Z",
          "iopub.status.idle": "2023-05-03T17:05:38.501025Z",
          "shell.execute_reply": "2023-05-03T17:05:38.500181Z"
        },
        "papermill": {
          "duration": 0.021377,
          "end_time": "2023-05-03T17:05:38.502364",
          "exception": false,
          "start_time": "2023-05-03T17:05:38.480987",
          "status": "completed"
        },
        "tags": [],
        "id": "ae2e204d",
        "outputId": "5d6bc124-be23-4dac-b3ae-13721d783f89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 7])\n"
          ]
        }
      ],
      "source": [
        "print(x[:2, -1])  # First two rows, last column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c953e24a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:38.534466Z",
          "iopub.status.busy": "2023-05-03T17:05:38.534122Z",
          "iopub.status.idle": "2023-05-03T17:05:38.540189Z",
          "shell.execute_reply": "2023-05-03T17:05:38.539093Z"
        },
        "papermill": {
          "duration": 0.022678,
          "end_time": "2023-05-03T17:05:38.541574",
          "exception": false,
          "start_time": "2023-05-03T17:05:38.518896",
          "status": "completed"
        },
        "tags": [],
        "id": "c953e24a",
        "outputId": "be3de724-fb5a-4b9e-efbd-a8627f8ec240",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n"
          ]
        }
      ],
      "source": [
        "print(x[1:3, :])  # Middle two rows"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07bc4c06",
      "metadata": {
        "papermill": {
          "duration": 0.014313,
          "end_time": "2023-05-03T17:05:38.573421",
          "exception": false,
          "start_time": "2023-05-03T17:05:38.559108",
          "status": "completed"
        },
        "tags": [],
        "id": "07bc4c06"
      },
      "source": [
        "### Dynamic Computation Graph and Backpropagation\n",
        "\n",
        "One of the main reasons for using PyTorch in Deep Learning projects is that we can automatically get **gradients/derivatives** of functions that we define.\n",
        "\n",
        "If we use weight matrices in our function that we want to learn, then those are called the **parameters** or simply the **weights**.\n",
        "\n",
        "- Given an input $\\mathbf{x}$, we define our function by **manipulating** that input.\n",
        "- As we manipulate our input, we are automatically creating a **computational graph**.\n",
        "- PyTorch is a **define-by-run** framework; this means that we can just do our manipulations, and PyTorch will keep track of that graph for us.\n",
        "\n",
        "So, to recap: the only thing we have to do is to compute the **output**, and then we can ask PyTorch to automatically get the **gradients**.\n",
        "\n",
        "The first thing we have to do is to specify which tensors require gradients.\n",
        "By default, when we create a tensor, it does not require gradients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61f8890b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:38.603383Z",
          "iopub.status.busy": "2023-05-03T17:05:38.602989Z",
          "iopub.status.idle": "2023-05-03T17:05:38.607792Z",
          "shell.execute_reply": "2023-05-03T17:05:38.606848Z"
        },
        "papermill": {
          "duration": 0.021477,
          "end_time": "2023-05-03T17:05:38.609188",
          "exception": false,
          "start_time": "2023-05-03T17:05:38.587711",
          "status": "completed"
        },
        "tags": [],
        "id": "61f8890b",
        "outputId": "e98ca0e8-6147-412c-9f4e-06a74084f855",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "x = torch.ones((3,))\n",
        "print(x.requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "461517a7",
      "metadata": {
        "papermill": {
          "duration": 0.014322,
          "end_time": "2023-05-03T17:05:38.641303",
          "exception": false,
          "start_time": "2023-05-03T17:05:38.626981",
          "status": "completed"
        },
        "tags": [],
        "id": "461517a7"
      },
      "source": [
        "We can change this for an existing tensor using the function `requires_grad_()` (underscore indicating that this is a in-place operation).\n",
        "Alternatively, when creating a tensor, you can pass the argument\n",
        "`requires_grad=True` to most initializers we have seen above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa0d2e59",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:38.671162Z",
          "iopub.status.busy": "2023-05-03T17:05:38.670848Z",
          "iopub.status.idle": "2023-05-03T17:05:38.675547Z",
          "shell.execute_reply": "2023-05-03T17:05:38.674676Z"
        },
        "papermill": {
          "duration": 0.02122,
          "end_time": "2023-05-03T17:05:38.676891",
          "exception": false,
          "start_time": "2023-05-03T17:05:38.655671",
          "status": "completed"
        },
        "tags": [],
        "id": "aa0d2e59",
        "outputId": "c7f7c214-402e-49b4-9bad-bfd851fe8ebc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "x.requires_grad_(True)\n",
        "print(x.requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66ae4399",
      "metadata": {
        "papermill": {
          "duration": 0.01437,
          "end_time": "2023-05-03T17:05:38.708101",
          "exception": false,
          "start_time": "2023-05-03T17:05:38.693731",
          "status": "completed"
        },
        "tags": [],
        "id": "66ae4399"
      },
      "source": [
        "In order to get familiar with the concept of a computation graph, we will create one for the following function:\n",
        "\n",
        "$$y = \\frac{1}{|x|}\\sum_i \\left[(x_i + 2)^2 + 3\\right]$$\n",
        "\n",
        "You could imagine that $x$ are our parameters, and we want to optimize (either maximize or minimize) the output $y$.\n",
        "For this, we want to obtain the gradients $\\partial y / \\partial \\mathbf{x}$.\n",
        "For our example, we'll use $\\mathbf{x}=[0,1,2]$ as our input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d59fe4a7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:38.738543Z",
          "iopub.status.busy": "2023-05-03T17:05:38.738139Z",
          "iopub.status.idle": "2023-05-03T17:05:38.745260Z",
          "shell.execute_reply": "2023-05-03T17:05:38.744241Z"
        },
        "papermill": {
          "duration": 0.02403,
          "end_time": "2023-05-03T17:05:38.746679",
          "exception": false,
          "start_time": "2023-05-03T17:05:38.722649",
          "status": "completed"
        },
        "tags": [],
        "id": "d59fe4a7",
        "outputId": "250871b9-f8ea-46a8-eebb-8c0bc73632f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X tensor([0., 1., 2.], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(3, dtype=torch.float32, requires_grad=True)  # Only float tensors can have gradients\n",
        "print(\"X\", x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42c93744",
      "metadata": {
        "papermill": {
          "duration": 0.014641,
          "end_time": "2023-05-03T17:05:38.780992",
          "exception": false,
          "start_time": "2023-05-03T17:05:38.766351",
          "status": "completed"
        },
        "tags": [],
        "id": "42c93744"
      },
      "source": [
        "Now let's build the computation graph step by step.\n",
        "You can combine multiple operations in a single line, but we will\n",
        "separate them here to get a better understanding of how each operation\n",
        "is added to the computation graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2186ab70",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:38.811854Z",
          "iopub.status.busy": "2023-05-03T17:05:38.811483Z",
          "iopub.status.idle": "2023-05-03T17:05:38.818329Z",
          "shell.execute_reply": "2023-05-03T17:05:38.817316Z"
        },
        "papermill": {
          "duration": 0.024097,
          "end_time": "2023-05-03T17:05:38.819849",
          "exception": false,
          "start_time": "2023-05-03T17:05:38.795752",
          "status": "completed"
        },
        "tags": [],
        "id": "2186ab70",
        "outputId": "5a17a637-e8ec-4065-84a7-b1814859d961",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y tensor(12.6667, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "a = x + 2\n",
        "b = a**2\n",
        "c = b + 3\n",
        "y = c.mean()\n",
        "print(\"Y\", y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84971c61",
      "metadata": {
        "papermill": {
          "duration": 0.014586,
          "end_time": "2023-05-03T17:05:38.853347",
          "exception": false,
          "start_time": "2023-05-03T17:05:38.838761",
          "status": "completed"
        },
        "tags": [],
        "id": "84971c61"
      },
      "source": [
        "Using the statements above, we have created a computation graph that looks similar to the figure below:\n",
        "\n",
        "<center style=\"width: 100%\"><img src=\"https://github.com/Lightning-AI/lightning-tutorials/raw/main/course_UvA-DL/01-introduction-to-pytorch/pytorch_computation_graph.svg\" width=\"200px\"></center>\n",
        "\n",
        "- We calculate $a$ based on the inputs $x$ and the constant $2$, $b$ is $a$ squared, and so on.\n",
        "- The visualization is an abstraction of the dependencies between inputs and outputs of the operations we have applied.\n",
        "- Each node of the computation graph has automatically defined a function for calculating the gradients with respect to its inputs, `grad_fn`.\n",
        "- We can perform backpropagation on the computation graph by calling the\n",
        "function `backward()` on the last output, which effectively calculates\n",
        "the gradients for each tensor that has the property\n",
        "`requires_grad=True`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efb525ed",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:38.883966Z",
          "iopub.status.busy": "2023-05-03T17:05:38.883652Z",
          "iopub.status.idle": "2023-05-03T17:05:38.974997Z",
          "shell.execute_reply": "2023-05-03T17:05:38.973812Z"
        },
        "papermill": {
          "duration": 0.109442,
          "end_time": "2023-05-03T17:05:38.977408",
          "exception": false,
          "start_time": "2023-05-03T17:05:38.867966",
          "status": "completed"
        },
        "tags": [],
        "id": "efb525ed"
      },
      "outputs": [],
      "source": [
        "y.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b10d974",
      "metadata": {
        "papermill": {
          "duration": 0.014629,
          "end_time": "2023-05-03T17:05:39.014668",
          "exception": false,
          "start_time": "2023-05-03T17:05:39.000039",
          "status": "completed"
        },
        "tags": [],
        "id": "3b10d974"
      },
      "source": [
        "`x.grad` will now contain the gradient $\\partial y/ \\partial \\mathcal{x}$, and this gradient indicates how a change in $\\mathbf{x}$ will affect output $y$ given the current input $\\mathbf{x}=[0,1,2]$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7940bafb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:39.045917Z",
          "iopub.status.busy": "2023-05-03T17:05:39.045530Z",
          "iopub.status.idle": "2023-05-03T17:05:39.052108Z",
          "shell.execute_reply": "2023-05-03T17:05:39.051132Z"
        },
        "papermill": {
          "duration": 0.024423,
          "end_time": "2023-05-03T17:05:39.053786",
          "exception": false,
          "start_time": "2023-05-03T17:05:39.029363",
          "status": "completed"
        },
        "tags": [],
        "id": "7940bafb",
        "outputId": "7e76732d-dcf9-4f46-c29c-63d7bb2b3e90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.3333, 2.0000, 2.6667])\n"
          ]
        }
      ],
      "source": [
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4adf8dda",
      "metadata": {
        "papermill": {
          "duration": 0.014831,
          "end_time": "2023-05-03T17:05:39.087254",
          "exception": false,
          "start_time": "2023-05-03T17:05:39.072423",
          "status": "completed"
        },
        "tags": [],
        "id": "4adf8dda"
      },
      "source": [
        "We can also verify these gradients by hand.\n",
        "We will calculate the gradients using the chain rule, in the same way as PyTorch did it:\n",
        "\n",
        "$$\\frac{\\partial y}{\\partial x_i} = \\frac{\\partial y}{\\partial c_i}\\frac{\\partial c_i}{\\partial b_i}\\frac{\\partial b_i}{\\partial a_i}\\frac{\\partial a_i}{\\partial x_i}$$\n",
        "\n",
        "Note that we have simplified this equation to index notation, and by using the fact that all operation besides the mean do not combine the elements in the tensor.\n",
        "The partial derivatives are:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial a_i}{\\partial x_i} = 1,\\hspace{1cm}\n",
        "\\frac{\\partial b_i}{\\partial a_i} = 2\\cdot a_i\\hspace{1cm}\n",
        "\\frac{\\partial c_i}{\\partial b_i} = 1\\hspace{1cm}\n",
        "\\frac{\\partial y}{\\partial c_i} = \\frac{1}{3}\n",
        "$$\n",
        "\n",
        "Hence, with the input being $\\mathbf{x}=[0,1,2]$, our gradients are $\\partial y/\\partial \\mathbf{x}=[4/3,2,8/3]$.\n",
        "The previous code cell should have printed the same result."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "920c5453",
      "metadata": {
        "papermill": {
          "duration": 0.014877,
          "end_time": "2023-05-03T17:05:39.116958",
          "exception": false,
          "start_time": "2023-05-03T17:05:39.102081",
          "status": "completed"
        },
        "tags": [],
        "id": "920c5453"
      },
      "source": [
        "### GPU support\n",
        "\n",
        "First, let's check whether you have a GPU available:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f37df15",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:39.147644Z",
          "iopub.status.busy": "2023-05-03T17:05:39.147403Z",
          "iopub.status.idle": "2023-05-03T17:05:39.152080Z",
          "shell.execute_reply": "2023-05-03T17:05:39.151196Z"
        },
        "papermill": {
          "duration": 0.021888,
          "end_time": "2023-05-03T17:05:39.153574",
          "exception": false,
          "start_time": "2023-05-03T17:05:39.131686",
          "status": "completed"
        },
        "tags": [],
        "id": "8f37df15",
        "outputId": "223664bf-05e8-43eb-efc3-607f8b2dc976",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the GPU available? True\n"
          ]
        }
      ],
      "source": [
        "gpu_avail = torch.cuda.is_available()\n",
        "print(f\"Is the GPU available? {gpu_avail}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d73d6e65",
      "metadata": {
        "papermill": {
          "duration": 0.014818,
          "end_time": "2023-05-03T17:05:39.186141",
          "exception": false,
          "start_time": "2023-05-03T17:05:39.171323",
          "status": "completed"
        },
        "tags": [],
        "id": "d73d6e65"
      },
      "source": [
        "- By default, all tensors you create are stored on the CPU.\n",
        "We can push a tensor to the GPU by using the function `.to(...)`, or `.cuda()`.\n",
        "- It is often a good practice to define a `device` object in your code which points to the GPU if you have one, and otherwise to the CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ca81537",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:39.217428Z",
          "iopub.status.busy": "2023-05-03T17:05:39.217062Z",
          "iopub.status.idle": "2023-05-03T17:05:39.223045Z",
          "shell.execute_reply": "2023-05-03T17:05:39.222058Z"
        },
        "papermill": {
          "duration": 0.024482,
          "end_time": "2023-05-03T17:05:39.225481",
          "exception": false,
          "start_time": "2023-05-03T17:05:39.200999",
          "status": "completed"
        },
        "tags": [],
        "id": "5ca81537",
        "outputId": "b8700a5a-2762-44c2-d245-aa7df92085d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "112a791e",
      "metadata": {
        "papermill": {
          "duration": 0.014864,
          "end_time": "2023-05-03T17:05:39.260973",
          "exception": false,
          "start_time": "2023-05-03T17:05:39.246109",
          "status": "completed"
        },
        "tags": [],
        "id": "112a791e"
      },
      "source": [
        "Now let's create a tensor and push it to the device:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49b3275f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:39.292071Z",
          "iopub.status.busy": "2023-05-03T17:05:39.291756Z",
          "iopub.status.idle": "2023-05-03T17:05:40.422151Z",
          "shell.execute_reply": "2023-05-03T17:05:40.420894Z"
        },
        "papermill": {
          "duration": 1.148884,
          "end_time": "2023-05-03T17:05:40.424769",
          "exception": false,
          "start_time": "2023-05-03T17:05:39.275885",
          "status": "completed"
        },
        "tags": [],
        "id": "49b3275f",
        "outputId": "0b4891d6-a3f7-4c2c-ef0b-3f494c45afde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "x = torch.zeros(2, 3)\n",
        "x = x.to(device)\n",
        "print(\"X\", x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f00df0b",
      "metadata": {
        "papermill": {
          "duration": 0.015425,
          "end_time": "2023-05-03T17:05:40.459629",
          "exception": false,
          "start_time": "2023-05-03T17:05:40.444204",
          "status": "completed"
        },
        "tags": [],
        "id": "5f00df0b"
      },
      "source": [
        "- In case you have a GPU, you should now see the attribute `device='cuda:0'` being printed next to your tensor.\n",
        "- The zero next to cuda indicates that this is the zero-th GPU device on your computer.\n",
        "\n",
        "We can also compare the runtime of a large matrix multiplication on the CPU with a operation on the GPU:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "858b43fc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:40.492999Z",
          "iopub.status.busy": "2023-05-03T17:05:40.492523Z",
          "iopub.status.idle": "2023-05-03T17:05:42.249581Z",
          "shell.execute_reply": "2023-05-03T17:05:42.248252Z"
        },
        "papermill": {
          "duration": 1.777167,
          "end_time": "2023-05-03T17:05:42.252196",
          "exception": false,
          "start_time": "2023-05-03T17:05:40.475029",
          "status": "completed"
        },
        "tags": [],
        "id": "858b43fc",
        "outputId": "a23e27f1-905f-4f97-c7a8-734a5f350c31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU time: 2.02440s\n",
            "GPU time: 0.08774s\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(5000, 5000)\n",
        "\n",
        "# CPU version\n",
        "start_time = time.time()\n",
        "_ = torch.matmul(x, x)\n",
        "end_time = time.time()\n",
        "print(f\"CPU time: {(end_time - start_time):6.5f}s\")\n",
        "\n",
        "# GPU version\n",
        "if torch.cuda.is_available():\n",
        "    x = x.to(device)\n",
        "    # CUDA is asynchronous, so we need to use different timing functions\n",
        "    start = torch.cuda.Event(enable_timing=True)\n",
        "    end = torch.cuda.Event(enable_timing=True)\n",
        "    start.record()\n",
        "    _ = torch.matmul(x, x)\n",
        "    end.record()\n",
        "    torch.cuda.synchronize()  # Waits for everything to finish running on the GPU\n",
        "    print(f\"GPU time: {0.001 * start.elapsed_time(end):6.5f}s\")  # Milliseconds to seconds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c1bbcdd",
      "metadata": {
        "papermill": {
          "duration": 0.015174,
          "end_time": "2023-05-03T17:05:42.287412",
          "exception": false,
          "start_time": "2023-05-03T17:05:42.272238",
          "status": "completed"
        },
        "tags": [],
        "id": "5c1bbcdd"
      },
      "source": [
        "As `matmul` operations are very common in neural networks, we can already see the great benefit of training a NN on a GPU.\n",
        "\n",
        "When generating random numbers, the seed between CPU and GPU is not synchronized.\n",
        "Hence, we need to set the seed on the GPU separately to ensure a reproducible code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c917d79b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-03T17:05:42.319889Z",
          "iopub.status.busy": "2023-05-03T17:05:42.319471Z",
          "iopub.status.idle": "2023-05-03T17:05:42.327421Z",
          "shell.execute_reply": "2023-05-03T17:05:42.326220Z"
        },
        "papermill": {
          "duration": 0.026338,
          "end_time": "2023-05-03T17:05:42.329097",
          "exception": false,
          "start_time": "2023-05-03T17:05:42.302759",
          "status": "completed"
        },
        "tags": [],
        "id": "c917d79b"
      },
      "outputs": [],
      "source": [
        "# GPU operations have a separate seed we also want to set\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "\n",
        "# Additionally, some operations on a GPU are implemented stochastic for efficiency\n",
        "# We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "colab,id,colab_type,-all",
      "formats": "ipynb,py:percent",
      "main_language": "python"
    },
    "language_info": {
      "name": "python"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 16.759473,
      "end_time": "2023-05-03T17:05:47.951877",
      "environment_variables": {},
      "exception": null,
      "input_path": "course_UvA-DL/01-introduction-to-pytorch/Introduction_to_PyTorch.ipynb",
      "output_path": ".notebooks/course_UvA-DL/01-introduction-to-pytorch.ipynb",
      "parameters": {},
      "start_time": "2023-05-03T17:05:31.192404",
      "version": "2.4.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}